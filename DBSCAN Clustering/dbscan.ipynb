{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5424f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wasserstein distance matrix\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import wasserstein_distance\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "BASE = Path(\"/home/njian29/Desktop\")\n",
    "INPUTS = {\n",
    "    \"sports\": BASE/\"filename_dates_packed_history_of_sports_tagged.csv\",\n",
    "    \"ideologies\": BASE/\"filename_dates_packed_history_of_ideologies_tagged.csv\",\n",
    "    \"objects\": BASE/\"filename_dates_packed_historical_objects_tagged.csv\",\n",
    "}\n",
    "WORDCOUNTS = {\n",
    "    \"sports\": BASE/\"filename_wordcounts_sports.csv\",\n",
    "    \"ideologies\": BASE/\"filename_wordcounts_ideologies.csv\",\n",
    "    \"objects\": BASE/\"filename_wordcounts_objects.csv\",\n",
    "}\n",
    "SCOPES = {\"top10\":0.10, \"top25\":0.25, \"top50\":0.50}\n",
    "\n",
    "MAX_YEAR, MIN_NUM_AS_YEAR = 2025, 32\n",
    "\n",
    "def extract_all_years(text: str):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    years = []\n",
    "    for m in re.finditer(r\"\\b(\\d{3,4})\\b\", text):\n",
    "        val = int(m.group(1))\n",
    "        if val >= MIN_NUM_AS_YEAR and val <= MAX_YEAR:\n",
    "            years.append(val)\n",
    "    return years\n",
    "\n",
    "def build_matrix(in_path: Path, langs_filter=None, pbar=None):\n",
    "    df = pd.read_csv(in_path, dtype=str, encoding=\"utf-8\")\n",
    "    date_cols = [c for c in df.columns if \"date\" in c.lower()]\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        lang = row[\"filename\"]\n",
    "        if langs_filter is not None and lang not in langs_filter:\n",
    "            if pbar: pbar.update(1)\n",
    "            continue\n",
    "        for c in date_cols:\n",
    "            for y in extract_all_years(row.get(c, \"\")):\n",
    "                records.append((lang, y))\n",
    "        if pbar: pbar.update(1)\n",
    "    years_df = pd.DataFrame(records, columns=[\"language\", \"year\"])\n",
    "    pivot = (years_df.groupby([\"language\", \"year\"]).size()\n",
    "             .reset_index(name=\"count\")\n",
    "             .pivot(index=\"language\", columns=\"year\", values=\"count\")\n",
    "             .fillna(0))\n",
    "    return pivot\n",
    "\n",
    "def compute_wasserstein_matrix(pivot: pd.DataFrame):\n",
    "    langs = pivot.index.tolist()\n",
    "    years = pivot.columns.values\n",
    "    histograms = pivot.values\n",
    "    n = len(langs)\n",
    "    dist_mat = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            h1, h2 = histograms[i], histograms[j]\n",
    "            xs = np.repeat(years, h1.astype(int))\n",
    "            ys = np.repeat(years, h2.astype(int))\n",
    "            if xs.size == 0 and ys.size == 0:\n",
    "                d = 0.0\n",
    "            elif xs.size == 0 or ys.size == 0:\n",
    "                d = np.inf\n",
    "            else:\n",
    "                d = wasserstein_distance(xs, ys)\n",
    "            dist_mat[i, j] = dist_mat[j, i] = d\n",
    "    return pd.DataFrame(dist_mat, index=langs, columns=langs)\n",
    "\n",
    "def main():\n",
    "    ordered_groups = [\"objects\", \"sports\", \"ideologies\"]\n",
    "\n",
    "    for group in ordered_groups:\n",
    "        path = INPUTS[group]\n",
    "        wc_path = WORDCOUNTS[group]\n",
    "        wc_df = pd.read_csv(wc_path, dtype={\"filename\": str, \"english_word_count\": int})\n",
    "        wc_df = wc_df.sort_values(\"english_word_count\", ascending=False).reset_index(drop=True)\n",
    "        langs_sorted = wc_df[\"filename\"].tolist()\n",
    "        total_langs = len(langs_sorted)\n",
    "        logging.info(f\"{group}: 总共有 {total_langs} 种语言\")\n",
    "\n",
    "        for scope, frac in SCOPES.items():\n",
    "            k = max(1, int(total_langs * frac))\n",
    "            top_langs = set(langs_sorted[:k])\n",
    "            logging.info(f\"{group}-{scope}: 取前 {k} 种语言\")\n",
    "\n",
    "            pivot = build_matrix(path, langs_filter=top_langs)\n",
    "            dist_mat = compute_wasserstein_matrix(pivot)\n",
    "\n",
    "            out_file = BASE / f\"wasserstein_{group}_{scope}.csv\"\n",
    "            dist_mat.to_csv(out_file)\n",
    "            logging.info(f\"[{group}-{scope}] 已保存 Wasserstein 距离矩阵: {out_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from adjustText import adjust_text\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "BASE = Path(\"/home/njian29/Desktop\")\n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"top10\": BASE / \"wasserstein_sports_top10.csv\",\n",
    "    \"top25\": BASE / \"wasserstein_sports_top25.csv\",\n",
    "    \"top50\": BASE / \"wasserstein_sports_top50.csv\",\n",
    "}\n",
    "\n",
    "CLUSTER_CONFIG = {\n",
    "    \"top10\":  {\"min_clusters\": 3, \"max_clusters\": 4}, \n",
    "    \"top25\":  {\"min_clusters\": 4, \"max_clusters\": 7}, \n",
    "    \"top50\":  {\"min_clusters\": 6, \"max_clusters\": 10}, \n",
    "}\n",
    "\n",
    "def cluster_dbscan(dist_mat: pd.DataFrame, eps=10, min_samples=2):\n",
    "    model = DBSCAN(metric=\"precomputed\", eps=eps, min_samples=min_samples)\n",
    "    labels = model.fit_predict(dist_mat.values)\n",
    "    return pd.DataFrame({\"language\": dist_mat.index, \"cluster_id\": labels})\n",
    "\n",
    "def auto_dbscan(dist_mat: pd.DataFrame, group=\"sports\", scope=\"top10\",\n",
    "                min_clusters=3, max_clusters=12):\n",
    "    eps_candidates = [3, 5, 7, 10, 12, 15, 20, 25, 30] \n",
    "    min_samples_candidates = [2, 3, 4, 5]\n",
    "\n",
    "    best_clusters, best_params = None, None\n",
    "    best_score = -1\n",
    "\n",
    "    for eps in eps_candidates:\n",
    "        for ms in min_samples_candidates:\n",
    "            clusters = cluster_dbscan(dist_mat, eps=eps, min_samples=ms)\n",
    "            labels = clusters[\"cluster_id\"].values\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = sum(labels == -1)\n",
    "            noise_ratio = n_noise / len(labels)\n",
    "\n",
    "            if n_clusters < min_clusters or n_clusters > max_clusters:\n",
    "                continue\n",
    "\n",
    "            score = n_clusters - 2 * noise_ratio\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_clusters, best_params = clusters, (eps, ms)\n",
    "\n",
    "    return best_clusters, best_params\n",
    "\n",
    "def plot_clusters(dist_mat: pd.DataFrame, clusters: pd.DataFrame,\n",
    "                  group=\"sports\", scope=\"top10\", params=None, tag=\"repel\"):\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    coords = mds.fit_transform(dist_mat.values)\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": coords[:, 0], \"y\": coords[:, 1],\n",
    "        \"language\": dist_mat.index,\n",
    "        \"cluster_id\": clusters[\"cluster_id\"].values\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    unique_clusters = sorted(df_plot[\"cluster_id\"].unique())\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "    texts = []\n",
    "    for cid, color in zip(unique_clusters, colors):\n",
    "        subset = df_plot[df_plot[\"cluster_id\"] == cid]\n",
    "        label = f\"Cluster {cid}\" if cid != -1 else \"Noise\"\n",
    "        plt.scatter(subset[\"x\"], subset[\"y\"], c=[color], s=40, alpha=0.8,\n",
    "                    label=label, edgecolors=\"k\")\n",
    "        for _, row in subset.iterrows():\n",
    "            texts.append(\n",
    "                plt.text(row[\"x\"], row[\"y\"], row[\"language\"], fontsize=8)\n",
    "            )\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=0.5),\n",
    "        force_points=1.0,\n",
    "        force_text=1.5,\n",
    "        expand_points=(1.4, 1.8),\n",
    "        expand_text=(1.4, 1.8),\n",
    "        only_move={'points': 'y', 'text': 'xy'}\n",
    "    )\n",
    "\n",
    "    plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.title(f\"DBSCAN Clusters ({group}-{scope}, {tag})\\nparams={params}\", fontsize=14)\n",
    "\n",
    "    out_fig = BASE / f\"dbscan_{group}_{scope}_{tag}.png\"\n",
    "    plt.savefig(out_fig, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    logging.info(f\"[{group}-{scope}] 聚类图已保存: {out_fig}\")\n",
    "\n",
    "def main():\n",
    "    group = \"sports\"\n",
    "    for scope, file_path in INPUT_FILES.items():\n",
    "        logging.info(f\"=== 处理 {scope} ({file_path.name}) ===\")\n",
    "        dist_mat = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "        cfg = CLUSTER_CONFIG[scope]\n",
    "        clusters, params = auto_dbscan(\n",
    "            dist_mat,\n",
    "            group=group,\n",
    "            scope=scope,\n",
    "            min_clusters=cfg[\"min_clusters\"],\n",
    "            max_clusters=cfg[\"max_clusters\"]\n",
    "        )\n",
    "\n",
    "        if clusters is None:\n",
    "            logging.error(f\"[{group}-{scope}] 未能找到合适的聚类参数。\")\n",
    "            continue\n",
    "\n",
    "        plot_clusters(dist_mat, clusters,\n",
    "                      group=group, scope=scope, params=params, tag=\"repel\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv files and dbcan filtered chart for objects\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as p\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from adjustText import adjust_text\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "BASE = Path(\"/home/njian29/Desktop\")\n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"top10\": BASE / \"wasserstein_objects_top10.csv\",\n",
    "    \"top25\": BASE / \"wasserstein_objects_top25.csv\",\n",
    "    \"top50\": BASE / \"wasserstein_objects_top50.csv\",\n",
    "}\n",
    "\n",
    "def cluster_dbscan(dist_mat: pd.DataFrame, eps=10, min_samples=2):\n",
    "    model = DBSCAN(metric=\"precomputed\", eps=eps, min_samples=min_samples)\n",
    "    labels = model.fit_predict(dist_mat.values)\n",
    "    return pd.DataFrame({\"language\": dist_mat.index, \"cluster_id\": labels})\n",
    "\n",
    "def auto_dbscan(dist_mat: pd.DataFrame, group=\"objects\", scope=\"top10\",\n",
    "                min_clusters=3, max_clusters=12):\n",
    "    eps_candidates = [5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    min_samples_candidates = [2, 3, 4, 5]\n",
    "\n",
    "    best_clusters, best_params = None, None\n",
    "    best_score = -1\n",
    "\n",
    "    for eps in eps_candidates:\n",
    "        for ms in min_samples_candidates:\n",
    "            clusters = cluster_dbscan(dist_mat, eps=eps, min_samples=ms)\n",
    "            labels = clusters[\"cluster_id\"].values\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = sum(labels == -1)\n",
    "            noise_ratio = n_noise / len(labels)\n",
    "\n",
    "            if n_clusters < min_clusters or n_clusters > max_clusters:\n",
    "                continue\n",
    "\n",
    "            score = n_clusters - 2 * noise_ratio\n",
    "            logging.info(f\"[{group}-{scope}] eps={eps}, min_samples={ms} → \"\n",
    "                         f\"簇数={n_clusters}, 噪声={n_noise}, score={score:.2f}\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_clusters, best_params = clusters, (eps, ms)\n",
    "\n",
    "    if best_clusters is None:\n",
    "        logging.warning(f\"[{group}-{scope}] 没有找到满足条件的参数。\")\n",
    "    else:\n",
    "        logging.info(f\"[{group}-{scope}] 最佳参数: eps={best_params[0]}, min_samples={best_params[1]} (score={best_score:.2f})\")\n",
    "\n",
    "    return best_clusters, best_params\n",
    "\n",
    "def assign_noise_to_nearest(dist_mat: pd.DataFrame, clusters: pd.DataFrame):\n",
    "    labels = clusters[\"cluster_id\"].values\n",
    "    noise_idxs = np.where(labels == -1)[0]\n",
    "\n",
    "    if len(noise_idxs) == 0:\n",
    "        return clusters\n",
    "\n",
    "    cluster_centers = {}\n",
    "    for cid in set(labels):\n",
    "        if cid == -1:\n",
    "            continue\n",
    "        member_idxs = np.where(labels == cid)[0]\n",
    "        cluster_centers[cid] = dist_mat.values[member_idxs].mean(axis=0)\n",
    "\n",
    "    for idx in noise_idxs:\n",
    "        dists = {cid: cluster_centers[cid][idx] for cid in cluster_centers}\n",
    "        nearest = min(dists, key=dists.get)\n",
    "        labels[idx] = nearest\n",
    "\n",
    "    clusters[\"cluster_id\"] = labels\n",
    "    return clusters\n",
    "\n",
    "def plot_clusters(dist_mat: pd.DataFrame, clusters: pd.DataFrame,\n",
    "                  group=\"objects\", scope=\"top10\", params=None, tag=\"filtered\"):\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    coords = mds.fit_transform(dist_mat.values)\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": coords[:, 0], \"y\": coords[:, 1],\n",
    "        \"language\": dist_mat.index,\n",
    "        \"cluster_id\": clusters[\"cluster_id\"].values\n",
    "    })\n",
    "\n",
    "    df_plot[\"dist\"] = np.sqrt(df_plot[\"x\"]**2 + df_plot[\"y\"]**2)\n",
    "    cutoff = df_plot[\"dist\"].quantile(0.90)\n",
    "    df_plot = df_plot[df_plot[\"dist\"] <= cutoff]\n",
    "\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    unique_clusters = sorted(df_plot[\"cluster_id\"].unique())\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "    texts = []\n",
    "    for cid, color in zip(unique_clusters, colors):\n",
    "        subset = df_plot[df_plot[\"cluster_id\"] == cid]\n",
    "        label = f\"Cluster {cid}\" if cid != -1 else \"Noise\"\n",
    "        plt.scatter(subset[\"x\"], subset[\"y\"], c=[color], s=40, alpha=0.8,\n",
    "                    label=label, edgecolors=\"k\")\n",
    "        for _, row in subset.iterrows():\n",
    "            texts.append(\n",
    "                plt.text(row[\"x\"], row[\"y\"], row[\"language\"], fontsize=8)\n",
    "            )\n",
    "\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.5),\n",
    "        force_points=0.5,\n",
    "        force_text=0.8,\n",
    "        expand_points=(1.2, 1.6),\n",
    "        expand_text=(1.2, 1.6),\n",
    "        only_move={'points':'y', 'text':'xy'}\n",
    "    )\n",
    "\n",
    "    plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.title(f\"DBSCAN Clusters ({group}-{scope}, {tag})\\nparams={params}\", fontsize=14)\n",
    "\n",
    "    out_fig = BASE / f\"dbscan_{group}_{scope}_{tag}.png\"\n",
    "    plt.savefig(out_fig, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    logging.info(f\"[{group}-{scope}] 聚类图已保存: {out_fig}\")\n",
    "\n",
    "def main():\n",
    "    group = \"objects\"\n",
    "    for scope, file_path in INPUT_FILES.items():\n",
    "        logging.info(f\"=== 处理 {scope} ({file_path.name}) ===\")\n",
    "        dist_mat = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "        clusters, params = auto_dbscan(dist_mat, group=group, scope=scope,\n",
    "                                       min_clusters=3, max_clusters=12)\n",
    "\n",
    "        if clusters is None:\n",
    "            logging.error(f\"[{group}-{scope}] 未能找到合适的聚类参数。\")\n",
    "            continue\n",
    "\n",
    "        out_csv = BASE / f\"dbscan_{group}_{scope}_original.csv\"\n",
    "        clusters.to_csv(out_csv, index=False)\n",
    "        logging.info(f\"[{group}-{scope}] 原始聚类结果已保存: {out_csv}\")\n",
    "\n",
    "        clusters_noisefree = assign_noise_to_nearest(dist_mat, clusters.copy())\n",
    "        out_csv2 = BASE / f\"dbscan_{group}_{scope}_noisefree.csv\"\n",
    "        clusters_noisefree.to_csv(out_csv2, index=False)\n",
    "        logging.info(f\"[{group}-{scope}] 去噪聚类结果已保存: {out_csv2}\")\n",
    "\n",
    "        plot_clusters(dist_mat, clusters_noisefree,\n",
    "                      group=group, scope=scope, params=params, tag=\"filtered\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7634436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv files and dbcan filtered chart  for ideologies\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from adjustText import adjust_text\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "BASE = Path(\"/home/njian29/Desktop\")\n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"top10\": BASE / \"wasserstein_ideologies_top10.csv\",\n",
    "    \"top25\": BASE / \"wasserstein_ideologies_top25.csv\",\n",
    "    \"top50\": BASE / \"wasserstein_ideologies_top50.csv\",\n",
    "}\n",
    "\n",
    "def cluster_dbscan(dist_mat: pd.DataFrame, eps=10, min_samples=2):\n",
    "    model = DBSCAN(metric=\"precomputed\", eps=eps, min_samples=min_samples)\n",
    "    labels = model.fit_predict(dist_mat.values)\n",
    "    return pd.DataFrame({\"language\": dist_mat.index, \"cluster_id\": labels})\n",
    "\n",
    "def auto_dbscan(dist_mat: pd.DataFrame, group=\"ideologies\", scope=\"top10\",\n",
    "                min_clusters=3, max_clusters=12):\n",
    "    eps_candidates = [5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    min_samples_candidates = [2, 3, 4, 5]\n",
    "\n",
    "    best_clusters, best_params = None, None\n",
    "    best_score = -1\n",
    "\n",
    "    for eps in eps_candidates:\n",
    "        for ms in min_samples_candidates:\n",
    "            clusters = cluster_dbscan(dist_mat, eps=eps, min_samples=ms)\n",
    "            labels = clusters[\"cluster_id\"].values\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = sum(labels == -1)\n",
    "            noise_ratio = n_noise / len(labels)\n",
    "\n",
    "            if n_clusters < min_clusters or n_clusters > max_clusters:\n",
    "                continue\n",
    "\n",
    "            score = n_clusters - 2 * noise_ratio\n",
    "            logging.info(f\"[{group}-{scope}] eps={eps}, min_samples={ms} → \"\n",
    "                         f\"簇数={n_clusters}, 噪声={n_noise}, score={score:.2f}\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_clusters, best_params = clusters, (eps, ms)\n",
    "\n",
    "    if best_clusters is None:\n",
    "        logging.warning(f\"[{group}-{scope}] 没有找到满足条件的参数。\")\n",
    "    else:\n",
    "        logging.info(f\"[{group}-{scope}] 最佳参数: eps={best_params[0]}, min_samples={best_params[1]} (score={best_score:.2f})\")\n",
    "\n",
    "    return best_clusters, best_params\n",
    "\n",
    "def assign_noise_to_nearest(dist_mat: pd.DataFrame, clusters: pd.DataFrame):\n",
    "    labels = clusters[\"cluster_id\"].values\n",
    "    noise_idxs = np.where(labels == -1)[0]\n",
    "\n",
    "    if len(noise_idxs) == 0:\n",
    "        return clusters\n",
    "\n",
    "    cluster_centers = {}\n",
    "    for cid in set(labels):\n",
    "        if cid == -1:\n",
    "            continue\n",
    "        member_idxs = np.where(labels == cid)[0]\n",
    "        cluster_centers[cid] = dist_mat.values[member_idxs].mean(axis=0)\n",
    "\n",
    "    for idx in noise_idxs:\n",
    "        dists = {cid: cluster_centers[cid][idx] for cid in cluster_centers}\n",
    "        nearest = min(dists, key=dists.get)\n",
    "        labels[idx] = nearest\n",
    "\n",
    "    clusters[\"cluster_id\"] = labels\n",
    "    return clusters\n",
    "\n",
    "# ========= 可视化 =========\n",
    "def plot_clusters(dist_mat: pd.DataFrame, clusters: pd.DataFrame,\n",
    "                  group=\"ideologies\", scope=\"top10\", params=None, tag=\"filtered\"):\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    coords = mds.fit_transform(dist_mat.values)\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": coords[:, 0], \"y\": coords[:, 1],\n",
    "        \"language\": dist_mat.index,\n",
    "        \"cluster_id\": clusters[\"cluster_id\"].values\n",
    "    })\n",
    "\n",
    "    df_plot[\"dist\"] = np.sqrt(df_plot[\"x\"]**2 + df_plot[\"y\"]**2)\n",
    "    cutoff = df_plot[\"dist\"].quantile(0.90)\n",
    "    df_plot = df_plot[df_plot[\"dist\"] <= cutoff]\n",
    "\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    unique_clusters = sorted(df_plot[\"cluster_id\"].unique())\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "    texts = []\n",
    "    for cid, color in zip(unique_clusters, colors):\n",
    "        subset = df_plot[df_plot[\"cluster_id\"] == cid]\n",
    "        label = f\"Cluster {cid}\" if cid != -1 else \"Noise\"\n",
    "        plt.scatter(subset[\"x\"], subset[\"y\"], c=[color], s=40, alpha=0.8,\n",
    "                    label=label, edgecolors=\"k\")\n",
    "        for _, row in subset.iterrows():\n",
    "            texts.append(\n",
    "                plt.text(row[\"x\"], row[\"y\"], row[\"language\"], fontsize=8)\n",
    "            )\n",
    "\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.5),\n",
    "        force_points=0.5,\n",
    "        force_text=0.8,\n",
    "        expand_points=(1.2, 1.6),\n",
    "        expand_text=(1.2, 1.6),\n",
    "        only_move={'points':'y', 'text':'xy'}\n",
    "    )\n",
    "\n",
    "    plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.title(f\"DBSCAN Clusters ({group}-{scope}, {tag})\\nparams={params}\", fontsize=14)\n",
    "\n",
    "    out_fig = BASE / f\"dbscan_{group}_{scope}_{tag}.png\"\n",
    "    plt.savefig(out_fig, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    logging.info(f\"[{group}-{scope}] 聚类图已保存: {out_fig}\")\n",
    "\n",
    "def main():\n",
    "    group = \"ideologies\"\n",
    "    for scope, file_path in INPUT_FILES.items():\n",
    "        logging.info(f\"=== 处理 {scope} ({file_path.name}) ===\")\n",
    "        dist_mat = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "        clusters, params = auto_dbscan(dist_mat, group=group, scope=scope,\n",
    "                                       min_clusters=3, max_clusters=12)\n",
    "\n",
    "        if clusters is None:\n",
    "            logging.error(f\"[{group}-{scope}] 未能找到合适的聚类参数。\")\n",
    "            continue\n",
    "\n",
    "        out_csv = BASE / f\"dbscan_{group}_{scope}_original.csv\"\n",
    "        clusters.to_csv(out_csv, index=False)\n",
    "        logging.info(f\"[{group}-{scope}] 原始聚类结果已保存: {out_csv}\")\n",
    "\n",
    "        clusters_noisefree = assign_noise_to_nearest(dist_mat, clusters.copy())\n",
    "        out_csv2 = BASE / f\"dbscan_{group}_{scope}_noisefree.csv\"\n",
    "        clusters_noisefree.to_csv(out_csv2, index=False)\n",
    "        logging.info(f\"[{group}-{scope}] 去噪聚类结果已保存: {out_csv2}\")\n",
    "\n",
    "        plot_clusters(dist_mat, clusters_noisefree,\n",
    "                      group=group, scope=scope, params=params, tag=\"filtered\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eb0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    " # csv files and dbcan filtered chart for sports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from adjustText import adjust_text\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "BASE = Path(\"/home/njian29/Desktop\")\n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"top10\": BASE / \"wasserstein_sports_top10.csv\",\n",
    "    \"top25\": BASE / \"wasserstein_sports_top25.csv\",\n",
    "    \"top50\": BASE / \"wasserstein_sports_top50.csv\",\n",
    "}\n",
    "\n",
    "CLUSTER_CONFIG = {\n",
    "    \"top10\":  {\"min_clusters\": 3, \"max_clusters\": 4},\n",
    "    \"top25\":  {\"min_clusters\": 4, \"max_clusters\": 7},  \n",
    "    \"top50\":  {\"min_clusters\": 6, \"max_clusters\": 10}, \n",
    "}\n",
    "\n",
    "def cluster_dbscan(dist_mat: pd.DataFrame, eps=10, min_samples=2):\n",
    "    model = DBSCAN(metric=\"precomputed\", eps=eps, min_samples=min_samples)\n",
    "    labels = model.fit_predict(dist_mat.values)\n",
    "    return pd.DataFrame({\"language\": dist_mat.index, \"cluster_id\": labels})\n",
    "\n",
    "def auto_dbscan(dist_mat: pd.DataFrame, group=\"sports\", scope=\"top10\",\n",
    "                min_clusters=3, max_clusters=12):\n",
    "    eps_candidates = [3, 5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    min_samples_candidates = [2, 3, 4, 5]\n",
    "\n",
    "    best_clusters, best_params = None, None\n",
    "    best_score = -1\n",
    "\n",
    "    for eps in eps_candidates:\n",
    "        for ms in min_samples_candidates:\n",
    "            clusters = cluster_dbscan(dist_mat, eps=eps, min_samples=ms)\n",
    "            labels = clusters[\"cluster_id\"].values\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = sum(labels == -1)\n",
    "            noise_ratio = n_noise / len(labels)\n",
    "\n",
    "            if n_clusters < min_clusters or n_clusters > max_clusters:\n",
    "                continue\n",
    "\n",
    "            score = n_clusters - 2 * noise_ratio\n",
    "            logging.info(f\"[{group}-{scope}] eps={eps}, min_samples={ms} → \"\n",
    "                         f\"簇数={n_clusters}, 噪声={n_noise}, score={score:.2f}\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_clusters, best_params = clusters, (eps, ms)\n",
    "\n",
    "    if best_clusters is None:\n",
    "        logging.warning(f\"[{group}-{scope}] 没有找到满足条件的参数。\")\n",
    "    else:\n",
    "        logging.info(f\"[{group}-{scope}] 最佳参数: eps={best_params[0]}, min_samples={best_params[1]} (score={best_score:.2f})\")\n",
    "\n",
    "    return best_clusters, best_params\n",
    "\n",
    "def assign_noise_to_nearest(dist_mat: pd.DataFrame, clusters: pd.DataFrame):\n",
    "    labels = clusters[\"cluster_id\"].values\n",
    "    noise_idxs = np.where(labels == -1)[0]\n",
    "\n",
    "    if len(noise_idxs) == 0:\n",
    "        return clusters\n",
    "\n",
    "    cluster_centers = {}\n",
    "    for cid in set(labels):\n",
    "        if cid == -1:\n",
    "            continue\n",
    "        member_idxs = np.where(labels == cid)[0]\n",
    "        cluster_centers[cid] = dist_mat.values[member_idxs].mean(axis=0)\n",
    "\n",
    "    for idx in noise_idxs:\n",
    "        dists = {cid: cluster_centers[cid][idx] for cid in cluster_centers}\n",
    "        nearest = min(dists, key=dists.get)\n",
    "        labels[idx] = nearest\n",
    "\n",
    "    clusters[\"cluster_id\"] = labels\n",
    "    return clusters\n",
    "\n",
    "def plot_clusters(dist_mat: pd.DataFrame, clusters: pd.DataFrame,\n",
    "                  group=\"sports\", scope=\"top10\", params=None, tag=\"filtered\"):\n",
    "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    coords = mds.fit_transform(dist_mat.values)\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": coords[:, 0], \"y\": coords[:, 1],\n",
    "        \"language\": dist_mat.index,\n",
    "        \"cluster_id\": clusters[\"cluster_id\"].values\n",
    "    })\n",
    "\n",
    "    df_plot[\"dist\"] = np.sqrt(df_plot[\"x\"]**2 + df_plot[\"y\"]**2)\n",
    "    cutoff = df_plot[\"dist\"].quantile(0.90)\n",
    "    df_plot = df_plot[df_plot[\"dist\"] <= cutoff]\n",
    "\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    unique_clusters = sorted(df_plot[\"cluster_id\"].unique())\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "    texts = []\n",
    "    for cid, color in zip(unique_clusters, colors):\n",
    "        subset = df_plot[df_plot[\"cluster_id\"] == cid]\n",
    "        label = f\"Cluster {cid}\" if cid != -1 else \"Noise\"\n",
    "        plt.scatter(subset[\"x\"], subset[\"y\"], c=[color], s=40, alpha=0.8,\n",
    "                    label=label, edgecolors=\"k\")\n",
    "        for _, row in subset.iterrows():\n",
    "            texts.append(\n",
    "                plt.text(row[\"x\"], row[\"y\"], row[\"language\"], fontsize=8)\n",
    "            )\n",
    "\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.5),\n",
    "        force_points=0.5,\n",
    "        force_text=0.8,\n",
    "        expand_points=(1.2, 1.6),\n",
    "        expand_text=(1.2, 1.6),\n",
    "        only_move={'points':'y', 'text':'xy'}\n",
    "    )\n",
    "\n",
    "    plt.legend(title=\"Clusters\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.title(f\"DBSCAN Clusters ({group}-{scope}, {tag})\\nparams={params}\", fontsize=14)\n",
    "\n",
    "    out_fig = BASE / f\"dbscan_{group}_{scope}_{tag}.png\"\n",
    "    plt.savefig(out_fig, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    logging.info(f\"[{group}-{scope}] 聚类图已保存: {out_fig}\")\n",
    "\n",
    "def main():\n",
    "    group = \"sports\"\n",
    "    for scope, file_path in INPUT_FILES.items():\n",
    "        logging.info(f\"=== 处理 {scope} ({file_path.name}) ===\")\n",
    "        dist_mat = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "        cfg = CLUSTER_CONFIG[scope]\n",
    "        clusters, params = auto_dbscan(\n",
    "            dist_mat,\n",
    "            group=group,\n",
    "            scope=scope,\n",
    "            min_clusters=cfg[\"min_clusters\"],\n",
    "            max_clusters=cfg[\"max_clusters\"]\n",
    "        )\n",
    "\n",
    "        if clusters is None:\n",
    "            logging.error(f\"[{group}-{scope}] 未能找到合适的聚类参数。\")\n",
    "            continue\n",
    "\n",
    "        out_csv = BASE / f\"dbscan_{group}_{scope}_original.csv\"\n",
    "        clusters.to_csv(out_csv, index=False)\n",
    "\n",
    "        clusters_noisefree = assign_noise_to_nearest(dist_mat, clusters.copy())\n",
    "        out_csv2 = BASE / f\"dbscan_{group}_{scope}_noisefree.csv\"\n",
    "        clusters_noisefree.to_csv(out_csv2, index=False)\n",
    "\n",
    "        plot_clusters(dist_mat, clusters_noisefree,\n",
    "                      group=group, scope=scope, params=params, tag=\"filtered\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
